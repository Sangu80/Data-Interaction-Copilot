# Data-Interaction-Copilot

# ðŸ¤– Data-Interaction Copilot â€“ A Smarter Way to Explore Data

![copilot-banner](assets/banner.gif) <!-- Replace with actual image path -->

Welcome to my submission for **Part 2B** of the **Data Science Coding Test â€“ 12 May 2025**. This project is a compact, schema-aware data assistant â€” think of it as an "EDA Copilot" powered by large language models (LLMs), built for analysts who want powerful, conversational control over their data.

---

## ðŸš€ What It Does

This copilot allows users to explore tabular datasets using natural language. It provides an interactive command-line interface where prompts like:

> `"What are the top 5 features with missing values?"`

or

> `"Simulate a 0.5% increase in interest rates and show the impact on loan status"`  

...are translated into real, pre-validated actions like SQL queries, pandas transformations, or simulations.

---

## ðŸ›  Features

| Capability                  | Description                                                                 |
|----------------------------|-----------------------------------------------------------------------------|
| âœ… **Schema Awareness**     | Understands and uses dataset schema for intelligent prompts and validation |
| ðŸ’¬ **Natural Language UI**  | Uses OpenAIâ€™s API to interpret and map user queries to executable commands |
| ðŸ§ª **Secure Sandbox**       | All LLM calls are guarded â€” no dynamic `exec()` or `eval()`                |
| ðŸ”„ **Interactive Shell**    | Run `python your_tool.py` to start an interactive session                  |
| ðŸ§© **Fallback Support**     | Works even without an OpenAI key (manual commands)                         |
| ðŸ“Š **EDA Utilities**        | Built-in functions for quick insights, summaries, and simulations          |
| âœ¨ **Portable**             | Cross-platform compatible, â‰¤ 400 logical lines                             |

---

## ðŸ“‚ Project Structure

data-copilot/
â”‚
â”œâ”€â”€ your_tool.py # Main tool â€“ single self-contained file
â”œâ”€â”€ requirements.txt # Exact dependencies
â”œâ”€â”€ .env.example # Template for API keys
â”œâ”€â”€ demo.gif # [Optional] 2-min demo screencast
â”œâ”€â”€ assets/
â”‚ â”œâ”€â”€ banner.gif # Copilot banner / visual
â”‚ â””â”€â”€ screenshots.png # Additional UI or CLI visuals
â””â”€â”€ README.md


---

## ðŸŽ¬ Demo

![demo](assets/demo.gif) <!-- Replace with your actual demo image or screencast -->

> _"See it in action!"_  
Live demo screencast showing two interactions â€” schema understanding and a portfolio simulation.

---

## ðŸ§  Design Decisions

- Built a lightweight **command registry** to ensure **LLM safety** and controlled execution
- Provided **fallback CLI commands** to allow full functionality without an API key
- Focused on **modular actions** (EDA summary, column stats, simulations) to encourage reusability
- Kept it under **400 lines**, with clean docstrings and in-code comments

---

## ðŸ’¡ Possible Extensions

- Add **Pinecone / Weaviate** for vector search over schemas
- Embed **streamlit** or **Gradio UI** front-end for a visual interface
- Expand to support **multi-table joins** and basic **forecasting capabilities**

---

## ðŸ“¦ Setup & Usage

### Step 1: Clone and Install

```bash
git clone https://github.com/yourusername/data-copilot.git
cd data-copilot
pip install -r requirements.txt

### Step 2: Add Your API Key
bash
Copy
Edit
cp .env.example .env
# Open .env and add your OpenAI API key

Step 3: Launch the Copilot
bash
Copy
Edit
python your_tool.py

ðŸ”’ Safety First
No eval(), exec(), or shell command execution.
Only whitelisted functions are allowed to run via the LLM interface.

---

âœ… **To finish setup**:
- Replace image paths like `assets/banner.gif`, `assets/demo.gif`, or `assets/screenshots.png` with your actual files.
- Change the GitHub repo URL (`https://github.com/yourusername/...`) to your own.
- You can also embed the GIF using raw GitHub CDN links or use an external host like Imgur if preferred.

Let me know if you'd like a `requirements.txt`, `.env.example`, or help writing unit tests next!
